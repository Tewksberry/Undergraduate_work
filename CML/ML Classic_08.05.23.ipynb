{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bcb51aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rubric</th>\n",
       "      <th>text_lemm</th>\n",
       "      <th>title_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Политика</td>\n",
       "      <td>начинаться дальнейший переговорный процесс рос...</td>\n",
       "      <td>песков начало переговоры украина нужный полити...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Политика</td>\n",
       "      <td>официальный представитель кремль дмитрий песо...</td>\n",
       "      <td>песок москва ожидать готовность киев обсуждат...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Политика</td>\n",
       "      <td>представитель кремль дмитрий песок сообщать о...</td>\n",
       "      <td>кремль объяснять почему продолжаться спецопер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Политика</td>\n",
       "      <td>представитель кремль заявлять помимо преодоле...</td>\n",
       "      <td>кремль начало переговоры украина нужный полит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Политика</td>\n",
       "      <td>официальный представитель кремль дмитрий песо...</td>\n",
       "      <td>песок начинать переговоры россия украина нужн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256325</th>\n",
       "      <td>Наука</td>\n",
       "      <td>стационарный посадочный модуль insight достав...</td>\n",
       "      <td>американский посадочный модуль insight марс п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256326</th>\n",
       "      <td>Наука</td>\n",
       "      <td>устройство позволять выращивать растение косм...</td>\n",
       "      <td>устройство развитие растение космос участие ч...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256327</th>\n",
       "      <td>Наука</td>\n",
       "      <td>новый японский ракета носитель тяжелый класс ...</td>\n",
       "      <td>первый запуск новый японский ракета носитель ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256328</th>\n",
       "      <td>Наука</td>\n",
       "      <td>первый запуск новый ракета носитель h который...</td>\n",
       "      <td>первый запуск новый японский ракета h состоят...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256329</th>\n",
       "      <td>Наука</td>\n",
       "      <td>новый японский ракета носитель тяжелый класс ...</td>\n",
       "      <td>первый запуск новый японский ракета носитель ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256330 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          rubric                                          text_lemm   \n",
       "0       Политика  начинаться дальнейший переговорный процесс рос...  \\\n",
       "1       Политика   официальный представитель кремль дмитрий песо...   \n",
       "2       Политика   представитель кремль дмитрий песок сообщать о...   \n",
       "3       Политика   представитель кремль заявлять помимо преодоле...   \n",
       "4       Политика   официальный представитель кремль дмитрий песо...   \n",
       "...          ...                                                ...   \n",
       "256325     Наука   стационарный посадочный модуль insight достав...   \n",
       "256326     Наука   устройство позволять выращивать растение косм...   \n",
       "256327     Наука   новый японский ракета носитель тяжелый класс ...   \n",
       "256328     Наука   первый запуск новый ракета носитель h который...   \n",
       "256329     Наука   новый японский ракета носитель тяжелый класс ...   \n",
       "\n",
       "                                               title_lemm  \n",
       "0       песков начало переговоры украина нужный полити...  \n",
       "1        песок москва ожидать готовность киев обсуждат...  \n",
       "2        кремль объяснять почему продолжаться спецопер...  \n",
       "3        кремль начало переговоры украина нужный полит...  \n",
       "4        песок начинать переговоры россия украина нужн...  \n",
       "...                                                   ...  \n",
       "256325   американский посадочный модуль insight марс п...  \n",
       "256326   устройство развитие растение космос участие ч...  \n",
       "256327   первый запуск новый японский ракета носитель ...  \n",
       "256328   первый запуск новый японский ракета h состоят...  \n",
       "256329   первый запуск новый японский ракета носитель ...  \n",
       "\n",
       "[256330 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Импорт собранных и обработанных данных\n",
    "import pandas as pd\n",
    "\n",
    "# Для mac\n",
    "df_nlp = pd.read_csv(r'/Users/user/Documents/Mine/nlp/ML.csv')\n",
    "\n",
    "# Для win\n",
    "#df_ml = pd.read_csv(r'C:\\Users\\User\\Downloads\\ML.csv')\n",
    "\n",
    "df_ml = df_nlp.drop(df_nlp.columns[[0,2,3,4,5,6,7,8,9]], axis = 1)\n",
    "df_ml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f205bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кодирование целевой переменной. Формирование тестовой и обучающей выборок\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "rubrics_list = df_ml['rubric'].to_list()\n",
    "rubric_labels = encoder.fit_transform(rubrics_list)\n",
    "\n",
    "X = df_ml['text_lemm']\n",
    "y = rubric_labels\n",
    "\n",
    "rubrics = ['Политика', 'Общество', 'Экономика', 'В мире', 'Спорт', 'Происшествия', 'Культура', 'Технологии', 'Наука']\n",
    "my_tags = rubrics\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60d09c6",
   "metadata": {},
   "source": [
    "### Байесовский классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266dcbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def nb_classifier():\n",
    "    \n",
    "    nb = Pipeline ([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', MultinomialNB()),\n",
    "                   ])\n",
    "    \n",
    "    nb.fit(X_train, y_train)\n",
    "    y_pred = nb.predict(X_test)\n",
    "\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "nb_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0bf54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def opt_nb_classifier():\n",
    "    \n",
    "    nb_opt = Pipeline ([('vect', CountVectorizer()),\n",
    "                        ('tfidf', TfidfTransformer()),\n",
    "                        ('clf', MultinomialNB()),\n",
    "                       ])\n",
    "    \n",
    "    # Определяем параметры для сеточного поиска\n",
    "    parameters = {\n",
    "        'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'clf__alpha': (0.01, 0.1, 1.0),\n",
    "    }\n",
    "    \n",
    "    # Создаем объект сеточного поиска с 5-кратной перекрестной проверкой\n",
    "    grid_search = GridSearchCV(nb_opt, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "    \n",
    "    # Запуск сеточного поиска\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Получение лучших параметров\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    # Запуск модели с новыми параметрами\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Вывод оценки классификации по всем метрикам\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "opt_nb_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcd1374",
   "metadata": {},
   "source": [
    "### Метод опорных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bbddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def sgd_classifier():\n",
    "    \n",
    "    sgd = Pipeline ([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "                    ])\n",
    "\n",
    "    sgd.fit(X_train, y_train)\n",
    "    y_pred = sgd.predict(X_test)\n",
    "\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "sgd_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32d4160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def opt_sgd_classifier():\n",
    "    \n",
    "    sgd_opt = Pipeline ([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', SGDClassifier()),\n",
    "                        ])\n",
    "    \n",
    "    # Определяем параметры для сеточного поиска\n",
    "    parameters = {\n",
    "        'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'clf__alpha': [0.0001, 0.001, 0.01],\n",
    "        'clf__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    }\n",
    "    \n",
    "    # Создаем объект сеточного поиска с 5-кратной перекрестной проверкой\n",
    "    grid_search = GridSearchCV(sgd_opt, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "    \n",
    "    # Запуск сеточного поиска\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Получение лучших параметров\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    # Запуск модели с новыми параметрами\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Вывод оценки классификации по всем метрикам\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "opt_sgd_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c897fa",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8644b95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def logreg_classifier():\n",
    "\n",
    "    logreg = Pipeline ([('vect', CountVectorizer()),\n",
    "                        ('tfidf', TfidfTransformer()),\n",
    "                        ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "                       ])\n",
    "\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "logreg_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bbd4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def opt_logreg_classifier():\n",
    "    \n",
    "    logreg_opt = Pipeline ([('vect', CountVectorizer()),\n",
    "                            ('tfidf', TfidfTransformer()),\n",
    "                            ('clf', LogisticRegression()),\n",
    "                           ])\n",
    "    \n",
    "    # Определение сетки параметров для перебора\n",
    "    parameters = {\n",
    "        'clf__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'clf__penalty': ['l1', 'l2'],\n",
    "        'clf__class_weight': [None, 'balanced']\n",
    "    }\n",
    "\n",
    "    # Create the grid search object with 5-fold cross validation\n",
    "    grid_search = GridSearchCV(logreg_opt, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "    \n",
    "    # Fit the grid search object to the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best score and best parameters from the grid search\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    # Predict on the test data using the best model from the grid search\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Print the accuracy score and classification report\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "opt_logreg_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef07dbc",
   "metadata": {},
   "source": [
    "### Дерево решений "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19af9778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def dtree_classifier():\n",
    "    \n",
    "    dtree = Pipeline ([('vect', CountVectorizer()),\n",
    "                       ('tfidf', TfidfTransformer()),\n",
    "                       ('clf', DecisionTreeClassifier(max_depth = 100)),\n",
    "                      ])\n",
    "\n",
    "    dtree.fit(X_train, y_train)\n",
    "    y_pred = dtree.predict(X_test)\n",
    "\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "dtree_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f515f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def opt_dtree_classifier():\n",
    "    \n",
    "    dtree = Pipeline ([('vect', CountVectorizer()),\n",
    "                       ('tfidf', TfidfTransformer()),\n",
    "                       ('clf', DecisionTreeClassifier()),\n",
    "                      ])\n",
    "    \n",
    "    # Define the parameters for the grid search\n",
    "    parameters = {\n",
    "        'clf__criterion': ['gini', 'entropy'],\n",
    "        'clf__max_depth': [10, 100],\n",
    "        'clf__min_samples_split': [2, 5, 10],\n",
    "        'clf__min_samples_leaf': [1, 5],\n",
    "        'clf__class_weight': ['balanced'],\n",
    "    }\n",
    "    \n",
    "    # Создание объекта GridSearchCV с 5-кратной перекрестной проверкой\n",
    "    grid_search = GridSearchCV(dtree, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "    # Применение grid search для обучения модели\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Получение лучшего результата и лучших параметров из grid search\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    # Предсказание на тестовых данных с использованием лучшей модели из grid search\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Вывод оценки точности и отчета о классификации\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "opt_dtree_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5fc9fa",
   "metadata": {},
   "source": [
    "### Метод K ближайщих соседей KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc33b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def knn_classifier():\n",
    "\n",
    "    knn = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', KNeighborsClassifier(n_neighbors=3)),\n",
    "                   ])\n",
    "\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "knn_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61edf204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def opt_knn_classifier():\n",
    "    \n",
    "    knn = Pipeline ([('vect', CountVectorizer()),\n",
    "                       ('tfidf', TfidfTransformer()),\n",
    "                       ('clf', KNeighborsClassifier()),\n",
    "                      ])\n",
    "    \n",
    "    # Define the parameters for the grid search\n",
    "    parameters = {\n",
    "        'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "        'tfidf__use_idf': [True, False],\n",
    "        'clf__n_neighbors': [3, 5, 7],\n",
    "        'clf__weights': ['uniform', 'distance']\n",
    "    }\n",
    "    \n",
    "    # Создание объекта GridSearchCV с 5-кратной перекрестной проверкой\n",
    "    grid_search = GridSearchCV(knn, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "    # Применение grid search для обучения модели\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Получение лучшего результата и лучших параметров из grid search\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    # Предсказание на тестовых данных с использованием лучшей модели из grid search\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Вывод оценки точности и отчета о классификации\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "opt_knn_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b11db16",
   "metadata": {},
   "source": [
    "### Метод градиентного бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05970ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def gb_classifier():\n",
    "    \n",
    "    gb = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', GradientBoostingClassifier(max_depth=2, n_estimators=150,\n",
    "                                                       random_state=12, learning_rate=1)),\n",
    "                   ])\n",
    "\n",
    "    gb.fit(X_train, y_train)\n",
    "    y_pred = gb.predict(X_test)\n",
    "\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "gb_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4be575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def opt_gb_classifier():\n",
    "    \n",
    "    gb = Pipeline ([('vect', CountVectorizer()),\n",
    "                       ('tfidf', TfidfTransformer()),\n",
    "                       ('clf', GradientBoostingClassifier()),\n",
    "                      ])\n",
    "    \n",
    "    # Define the parameters for the grid search\n",
    "    parameters = {\n",
    "        'clf__n_estimators': [50, 100, 150],\n",
    "        'clf__max_depth': [3, 5, 7],\n",
    "        'clf__learning_rate': [0.01, 0.1, 1]\n",
    "    }\n",
    "    \n",
    "    # Создание объекта GridSearchCV с 5-кратной перекрестной проверкой\n",
    "    grid_search = GridSearchCV(gb, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "    # Применение grid search для обучения модели\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Получение лучшего результата и лучших параметров из grid search\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    # Предсказание на тестовых данных с использованием лучшей модели из grid search\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Вывод оценки точности и отчета о классификации\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "opt_knn_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951fdeac",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ef5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def rf_classifier():\n",
    "\n",
    "    rf = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', RandomForestClassifier(n_estimators=10, random_state=1))\n",
    "                  ])\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "rf_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45178a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def opt_rf_classifier():\n",
    "    \n",
    "    rf_opt = Pipeline ([('vect', CountVectorizer()),\n",
    "                        ('tfidf', TfidfTransformer()),\n",
    "                        ('clf', RandomForestClassifier()),\n",
    "                       ])\n",
    "    \n",
    "    # Define the parameters for the grid search\n",
    "    parameters = {\n",
    "        'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'clf__max_depth': [5, 10, 15, None],\n",
    "        'clf__min_samples_split': [2, 5, 10],\n",
    "    }\n",
    "    \n",
    "    # Create the grid search object with 5-fold cross validation\n",
    "    grid_search = GridSearchCV(rf_opt, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "    \n",
    "    # Fit the grid search object to the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best score and best parameters from the grid search\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    # Predict on the test data using the best model from the grid search\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Print the accuracy score and classification report\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "opt_rf_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69b32c1",
   "metadata": {},
   "source": [
    "### Стекинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ffe7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def stack_classifier():\n",
    "    estimators = [('lr', LogisticRegression()), ('dt', DecisionTreeClassifier())]\n",
    "\n",
    "    stack = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', StackingClassifier(estimators=estimators, final_estimator=SVC()))\n",
    "                     ])\n",
    "\n",
    "    stack.fit(X_train, y_train)\n",
    "    y_pred = stack.predict(X_test)\n",
    "\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "stack_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26132128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def opt_stack_classifier():\n",
    "    estimators = [('lr', LogisticRegression()), ('dt', DecisionTreeClassifier())]\n",
    "\n",
    "    stack_opt = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', StackingClassifier(estimators=estimators, final_estimator=SVC()))\n",
    "                     ])\n",
    "    \n",
    "    # Define the parameters for the grid search\n",
    "    parameters = {\n",
    "        'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'clf__final_estimator__C': [0.1, 1, 10],\n",
    "        'clf__stack_method': ['auto', 'predict_proba', 'decision_function'],\n",
    "        'clf__passthrough': [True, False],\n",
    "    }\n",
    "    \n",
    "    # Create the grid search object with 5-fold cross validation\n",
    "    grid_search = GridSearchCV(stack_opt, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "    \n",
    "    # Fit the grid search object to the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best score and best parameters from the grid search\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    # Predict on the test data using the best model from the grid search\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Print the accuracy score and classification report\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "opt_stack_classifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f85f2",
   "metadata": {},
   "source": [
    "### Бэггинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b22e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "def bag_classifier():\n",
    "    bag = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', BaggingClassifier(base_estimator=LogisticRegression(), n_estimators=50, random_state=12))\n",
    "                   ])\n",
    "\n",
    "    bag.fit(X_train, y_train)\n",
    "    y_pred = bag.predict(X_test)\n",
    "\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "bag_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17ae82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def opt_bag_classifier():\n",
    "    \n",
    "    bag_opt = Pipeline ([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', BaggingClassifier(base_estimator=LogisticRegression(), random_state=12)),\n",
    "                        ])\n",
    "    \n",
    "    # Define the parameters for the grid search\n",
    "    parameters = {\n",
    "        'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'clf__n_estimators': [10, 20, 30],\n",
    "        'clf__max_samples': [0.5, 1.0],\n",
    "        'clf__max_features': [0.5, 1.0],\n",
    "    }\n",
    "    \n",
    "    # Create the grid search object with 5-fold cross validation\n",
    "    grid_search = GridSearchCV(bag_opt, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "    \n",
    "    # Fit the grid search object to the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best score and best parameters from the grid search\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    # Predict on the test data using the best model from the grid search\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Print the accuracy score and classification report\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "opt_bag_classifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0596dc9",
   "metadata": {},
   "source": [
    "### Адаптивный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24ae829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "def adb_classifier():\n",
    "    adb = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2), n_estimators=100, random_state=12))\n",
    "                   ])\n",
    "\n",
    "    adb.fit(X_train, y_train)\n",
    "    y_pred = adb.predict(X_test)\n",
    "\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "adb_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eda9815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def opt_adb_classifier():\n",
    "    \n",
    "    adb_opt = Pipeline ([('vect', CountVectorizer()),\n",
    "                        ('tfidf', TfidfTransformer()),\n",
    "                        ('clf', AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2))),\n",
    "                       ])\n",
    "    \n",
    "    # Define the parameters for the grid search\n",
    "    parameters = {\n",
    "        'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'clf__n_estimators': [50, 100, 200],\n",
    "    }\n",
    "    \n",
    "    # Create the grid search object with 5-fold cross validation\n",
    "    grid_search = GridSearchCV(adb_opt, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "    \n",
    "    # Fit the grid search object to the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best score and best parameters from the grid search\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    # Predict on the test data using the best model from the grid search\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Print the accuracy score and classification report\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "opt_adb_classifier()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
