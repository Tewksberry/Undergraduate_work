{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcb51aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт собранных и обработанных данных\n",
    "import pandas as pd\n",
    "\n",
    "# Для mac\n",
    "df_nlp = pd.read_csv(r'/Users/user/Documents/Mine/nlp/ML.csv')\n",
    "\n",
    "# Для win\n",
    "#df_ml = pd.read_csv(r'C:\\Users\\User\\Downloads\\ML.csv')\n",
    "\n",
    "df_ml = df_nlp.drop(df_nlp.columns[[0,2,3,4,5,6,7,8,9]], axis = 1)\n",
    "df_ml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f205bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кодирование целевой переменной. Формирование тестовой и обучающей выборок\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "rubrics_list = df_ml['rubric'].to_list()\n",
    "rubric_labels = encoder.fit_transform(rubrics_list)\n",
    "\n",
    "X = df_ml['text_lemm']\n",
    "y = rubric_labels\n",
    "\n",
    "rubrics = ['Политика', 'Общество', 'Экономика', 'В мире', 'Спорт', 'Происшествия', 'Культура', 'Технологии', 'Наука']\n",
    "my_tags = rubrics\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60d09c6",
   "metadata": {},
   "source": [
    "### Байесовский классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266dcbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def nb_classifier():\n",
    "    \n",
    "    nb = Pipeline ([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', MultinomialNB()),\n",
    "                   ])\n",
    "    \n",
    "    nb.fit(X_train, y_train)\n",
    "    y_pred = nb.predict(X_test)\n",
    "\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "nb_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0bf54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def opt_nb_classifier():\n",
    "    \n",
    "    nb_opt = Pipeline ([('vect', CountVectorizer()),\n",
    "                        ('tfidf', TfidfTransformer()),\n",
    "                        ('clf', MultinomialNB()),\n",
    "                       ])\n",
    "    \n",
    "    # Определяем параметры для сеточного поиска\n",
    "    parameters = {\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'clf__alpha': (0.01, 0.1, 1.0),\n",
    "    }\n",
    "    \n",
    "    # Создаем объект сеточного поиска с 5-кратной перекрестной проверкой\n",
    "    grid_search = GridSearchCV(nb_opt, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "    \n",
    "    # Запуск сеточного поиска\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Получение лучших параметров\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    # Запуск модели с новыми параметрами\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Вывод оценки классификации по всем метрикам\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "opt_nb_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcd1374",
   "metadata": {},
   "source": [
    "### Метод опорных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bbddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def sgd_classifier():\n",
    "    \n",
    "    sgd = Pipeline ([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier()),\n",
    "                    ])\n",
    "\n",
    "    sgd.fit(X_train, y_train)\n",
    "    y_pred = sgd.predict(X_test)\n",
    "\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "sgd_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32d4160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def opt_sgd_classifier():\n",
    "    \n",
    "    sgd_opt = Pipeline ([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', SGDClassifier()),\n",
    "                        ])\n",
    "    \n",
    "    # Определяем параметры для сеточного поиска\n",
    "    parameters = {\n",
    "        'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "        'clf__alpha': [0.000001],\n",
    "        'clf__penalty': ['l2'],\n",
    "    }\n",
    "    \n",
    "    # Создаем объект сеточного поиска с 5-кратной перекрестной проверкой\n",
    "    grid_search = GridSearchCV(sgd_opt, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "    \n",
    "    # Запуск сеточного поиска\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Получение лучших параметров\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    # Запуск модели с новыми параметрами\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Вывод оценки классификации по всем метрикам\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "opt_sgd_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c897fa",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8644b95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def logreg_classifier():\n",
    "\n",
    "    logreg = Pipeline ([('vect', CountVectorizer()),\n",
    "                        ('tfidf', TfidfTransformer()),\n",
    "                        ('clf', LogisticRegression()),\n",
    "                       ])\n",
    "\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "logreg_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bbd4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def opt_logreg_classifier():\n",
    "    \n",
    "    logreg_opt = Pipeline ([('vect', CountVectorizer()),\n",
    "                            ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
    "                            ('clf', LogisticRegression(solver='liblinear')),\n",
    "                           ])\n",
    "    \n",
    "    # Определение сетки параметров для перебора\n",
    "    parameters = {\n",
    "        'clf__C': [15],\n",
    "        'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "        'clf__penalty': ['l2'],\n",
    "        'clf__class_weight': [None, 'balanced']\n",
    "    }\n",
    "\n",
    "    # Create the grid search object with 5-fold cross validation\n",
    "    grid_search = GridSearchCV(logreg_opt, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "    \n",
    "    # Fit the grid search object to the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best score and best parameters from the grid search\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    # Predict on the test data using the best model from the grid search\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Print the accuracy score and classification report\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "opt_logreg_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef07dbc",
   "metadata": {},
   "source": [
    "### Дерево решений "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19af9778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def dtree_classifier():\n",
    "    \n",
    "    dtree = Pipeline ([('vect', CountVectorizer()),\n",
    "                       ('tfidf', TfidfTransformer()),\n",
    "                       ('clf', DecisionTreeClassifier()),\n",
    "                      ])\n",
    "\n",
    "    dtree.fit(X_train, y_train)\n",
    "    y_pred = dtree.predict(X_test)\n",
    "\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "dtree_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f515f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def opt_dtree_classifier():\n",
    "    \n",
    "    dtree = Pipeline ([('vect', CountVectorizer()),\n",
    "                       ('tfidf', TfidfTransformer()),\n",
    "                       ('clf', DecisionTreeClassifier()),\n",
    "                      ])\n",
    "    \n",
    "    # Define the parameters for the grid search\n",
    "    parameters = {\n",
    "        'clf__criterion': ['gini', 'entropy'],\n",
    "        'clf__max_depth': [10, 100],\n",
    "        'clf__min_samples_split': [2, 5, 10],\n",
    "        'clf__min_samples_leaf': [1, 5],\n",
    "        'clf__class_weight': ['balanced'],\n",
    "    }\n",
    "    \n",
    "    # Создание объекта GridSearchCV с 5-кратной перекрестной проверкой\n",
    "    grid_search = GridSearchCV(dtree, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "    # Применение grid search для обучения модели\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Получение лучшего результата и лучших параметров из grid search\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    # Предсказание на тестовых данных с использованием лучшей модели из grid search\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Вывод оценки точности и отчета о классификации\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "opt_dtree_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5fc9fa",
   "metadata": {},
   "source": [
    "### Метод K ближайщих соседей KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc33b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def knn_classifier():\n",
    "\n",
    "    knn = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', KNeighborsClassifier()),\n",
    "                   ])\n",
    "\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "knn_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61edf204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def opt_knn_classifier():\n",
    "    \n",
    "    knn = Pipeline ([('vect', CountVectorizer()),\n",
    "                       ('tfidf', TfidfTransformer()),\n",
    "                       ('clf', KNeighborsClassifier()),\n",
    "                      ])\n",
    "    \n",
    "    # Define the parameters for the grid search\n",
    "    parameters = {\n",
    "        'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "        'tfidf__use_idf': [True, False],\n",
    "        'clf__n_neighbors': [3, 5, 7],\n",
    "        'clf__weights': ['uniform', 'distance']\n",
    "    }\n",
    "    \n",
    "    # Создание объекта GridSearchCV с 5-кратной перекрестной проверкой\n",
    "    grid_search = GridSearchCV(knn, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "    # Применение grid search для обучения модели\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Получение лучшего результата и лучших параметров из grid search\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    # Предсказание на тестовых данных с использованием лучшей модели из grid search\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Вывод оценки точности и отчета о классификации\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "opt_knn_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69b32c1",
   "metadata": {},
   "source": [
    "### Стекинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ffe7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def stack_classifier():\n",
    "    estimators = [('lr', LogisticRegression()), ('dt', DecisionTreeClassifier())]\n",
    "\n",
    "    stack = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', StackingClassifier(estimators=estimators, final_estimator=SVC()))\n",
    "                     ])\n",
    "\n",
    "    stack.fit(X_train, y_train)\n",
    "    y_pred = stack.predict(X_test)\n",
    "\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "stack_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26132128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def opt_stack_classifier():\n",
    "    estimators = [('lr', LogisticRegression()), ('dt', DecisionTreeClassifier())]\n",
    "\n",
    "    stack_opt = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', StackingClassifier(estimators=estimators, final_estimator=SVC()))\n",
    "                     ])\n",
    "    \n",
    "    # Define the parameters for the grid search\n",
    "    parameters = {\n",
    "        'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'clf__final_estimator__C': [0.1, 1, 10],\n",
    "        'clf__stack_method': ['auto', 'predict_proba', 'decision_function'],\n",
    "        'clf__passthrough': [True, False],\n",
    "    }\n",
    "    \n",
    "    # Create the grid search object with 5-fold cross validation\n",
    "    grid_search = GridSearchCV(stack_opt, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "    \n",
    "    # Fit the grid search object to the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best score and best parameters from the grid search\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    # Predict on the test data using the best model from the grid search\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Print the accuracy score and classification report\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "opt_stack_classifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f85f2",
   "metadata": {},
   "source": [
    "### Бэггинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b22e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "def bag_classifier():\n",
    "    bag = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', BaggingClassifier(base_estimator=LogisticRegression()))\n",
    "                   ])\n",
    "\n",
    "    bag.fit(X_train, y_train)\n",
    "    y_pred = bag.predict(X_test)\n",
    "\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "bag_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17ae82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def opt_bag_classifier():\n",
    "    \n",
    "    bag_opt = Pipeline ([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', BaggingClassifier(base_estimator=LogisticRegression(), random_state=12)),\n",
    "                        ])\n",
    "    \n",
    "    # Define the parameters for the grid search\n",
    "    parameters = {\n",
    "        'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'clf__n_estimators': [10, 20, 30],\n",
    "        'clf__max_samples': [0.5, 1.0],\n",
    "        'clf__max_features': [0.5, 1.0],\n",
    "    }\n",
    "    \n",
    "    # Create the grid search object with 5-fold cross validation\n",
    "    grid_search = GridSearchCV(bag_opt, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "    \n",
    "    # Fit the grid search object to the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best score and best parameters from the grid search\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    # Predict on the test data using the best model from the grid search\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Print the accuracy score and classification report\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "opt_bag_classifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951fdeac",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ef5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def rf_classifier():\n",
    "\n",
    "    rf = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', RandomForestClassifier())\n",
    "                  ])\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "rf_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45178a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def opt_rf_classifier():\n",
    "    \n",
    "    rf_opt = Pipeline ([('vect', CountVectorizer()),\n",
    "                        ('tfidf', TfidfTransformer()),\n",
    "                        ('clf', RandomForestClassifier()),\n",
    "                       ])\n",
    "    \n",
    "    # Define the parameters for the grid search\n",
    "    parameters = {\n",
    "        'vect__ngram_range': [(1, 2)],\n",
    "    }\n",
    "    \n",
    "    # Create the grid search object with 5-fold cross validation\n",
    "    grid_search = GridSearchCV(rf_opt, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "    \n",
    "    # Fit the grid search object to the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best score and best parameters from the grid search\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    # Predict on the test data using the best model from the grid search\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Print the accuracy score and classification report\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "opt_rf_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b11db16",
   "metadata": {},
   "source": [
    "### Метод градиентного бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05970ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def gb_classifier():\n",
    "    \n",
    "    gb = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', GradientBoostingClassifier(loss='deviance')),\n",
    "                   ])\n",
    "\n",
    "    gb.fit(X_train, y_train)\n",
    "    y_pred = gb.predict(X_test)\n",
    "\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "gb_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4be575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def opt_gb_classifier():\n",
    "    \n",
    "    gb = Pipeline ([('vect', CountVectorizer()),\n",
    "                       ('tfidf', TfidfTransformer()),\n",
    "                       ('clf', GradientBoostingClassifier()),\n",
    "                      ])\n",
    "    \n",
    "    # Define the parameters for the grid search\n",
    "    parameters = {\n",
    "        'vect__ngram_range': [(1, 2)],\n",
    "    }\n",
    "    \n",
    "    # Создание объекта GridSearchCV с 5-кратной перекрестной проверкой\n",
    "    grid_search = GridSearchCV(gb, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "    # Применение grid search для обучения модели\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Получение лучшего результата и лучших параметров из grid search\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    # Предсказание на тестовых данных с использованием лучшей модели из grid search\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Вывод оценки точности и отчета о классификации\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "    \n",
    "    return round(accuracy_score(y_pred, y_test), 2)\n",
    "\n",
    "opt_gb_classifier()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
